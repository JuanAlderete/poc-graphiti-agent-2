# =============================================================================
# NOVOLABS AI ENGINE - Variables de Entorno
# Copiar a .env y completar. NUNCA commitear .env con valores reales.
# =============================================================================
#
# CAMBIO DE PROVEEDOR:
#   1. Editar LLM_PROVIDER en este archivo
#   2. Si cambias entre openai y ollama por primera vez: bash scripts/reset_db.sh
#      (necesario porque el tamaño del vector cambia: 1536 ↔ 768)
#   3. docker compose up --build
#
# =============================================================================

# =============================================================================
# PROVEEDOR LLM — LA ÚNICA VARIABLE QUE CAMBIA TODO
# =============================================================================
# Opciones: openai | ollama | gemini

LLM_PROVIDER=openai

# =============================================================================
# OPCIÓN A: OPENAI (producción)
# =============================================================================
# Descomentar y completar para usar OpenAI

OPENAI_API_KEY=sk-...

# Dejar vacíos para usar los defaults del proveedor:
# DEFAULT_MODEL=gpt-4.1-mini        # auto-configurado
# FALLBACK_MODEL=gpt-4.1-mini       # auto-configurado
# EMBEDDING_MODEL=text-embedding-3-small  # auto-configurado (1536 dims)
# OPENAI_BASE_URL=                   # dejar vacío para OpenAI oficial

# =============================================================================
# OPCIÓN B: OLLAMA LOCAL (desarrollo / testing)
# =============================================================================
# Para usar Ollama, cambiar LLM_PROVIDER=ollama arriba y descomentar:

# OPENAI_API_KEY=ollama               # valor especial, Ollama no valida keys
# OPENAI_BASE_URL=http://localhost:11434/v1   # o http://ollama:11434/v1 en Docker
#
# Modelos recomendados (ejecutar antes: ollama pull <modelo>):
# DEFAULT_MODEL=llama3.1:8b           # auto-configurado
# FALLBACK_MODEL=llama3.1:8b          # auto-configurado
# EMBEDDING_MODEL=nomic-embed-text    # auto-configurado (768 dims)
#
# En Ollama el MONTHLY_BUDGET_USD se ignora (costo = $0)

# =============================================================================
# OPCIÓN C: GEMINI (alternativa económica)
# =============================================================================
# Para usar Gemini, cambiar LLM_PROVIDER=gemini arriba y descomentar:

# GEMINI_API_KEY=AIza...
# DEFAULT_MODEL=gemini-1.5-flash      # auto-configurado
# EMBEDDING_MODEL=text-embedding-004  # auto-configurado (768 dims)

# =============================================================================
# POSTGRESQL
# =============================================================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=novolabs
POSTGRES_USER=novolabs
POSTGRES_PASSWORD=cambia_este_password

# =============================================================================
# NEO4J — OPCIONAL (Fase 2+)
# En Fase 1 mantener ENABLE_GRAPH=false
# Para activar: docker compose --profile graph up
# =============================================================================
ENABLE_GRAPH=false
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=

# =============================================================================
# BUDGET GUARD
# Solo activo con OpenAI/Gemini. Se ignora automáticamente en Ollama.
# =============================================================================
MONTHLY_BUDGET_USD=50
BUDGET_ALERT_THRESHOLD_1=0.70
BUDGET_ALERT_THRESHOLD_2=0.90
BUDGET_TRACKING_FILE=logs/monthly_budget.json

# =============================================================================
# NOTION
# Obtener token en: https://www.notion.so/my-integrations
# (Completar en Módulo 1.2)
# =============================================================================
NOTION_TOKEN=secret_...
NOTION_REELS_DB=
NOTION_EMAIL_DB=
NOTION_HISTORIA_DB=
NOTION_ADS_DB=
NOTION_RUNS_DB=
NOTION_RULES_DB=

# =============================================================================
# TELEGRAM
# Obtener token en: @BotFather en Telegram
# (Completar en Módulo 1.5)
# =============================================================================
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=

# =============================================================================
# APP
# =============================================================================
LOG_LEVEL=INFO
ENVIRONMENT=development
API_PORT=8000
MAX_CONCURRENT_GENERATIONS=5